{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e2995b-d376-4b95-a1b2-d0e2ff727380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a02355-8656-4fae-b1b1-fdf35f34c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = pd.read_csv('temp/Final_Dataset.csv')\n",
    "file2 = pd.read_csv('temp/maliciousOnly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89949605-2afe-4ae4-9879-5d5c023e0dde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tx_hash</th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>in_btc</th>\n",
       "      <th>out_btc</th>\n",
       "      <th>total_btc</th>\n",
       "      <th>mean_in_btc</th>\n",
       "      <th>mean_out_btc</th>\n",
       "      <th>in_malicious</th>\n",
       "      <th>out_malicious</th>\n",
       "      <th>is_malicious</th>\n",
       "      <th>all_malicious</th>\n",
       "      <th>out_and_tx_malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0437cd7f8525ceed2324359c2d0ba26006d92d856a9c20...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f4184fc596403b9d638783cf57adfe4c75c605f6356fbc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ea44e97271691990157559d0bdd9959e02790c34db6c00...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a16f3ce4dd5deb92d98ef5cf8afeaf0775ebca408f708b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>591e91f809d716912ca1d4a9295e70c3e78bab077683f7...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000100</th>\n",
       "      <td>3a66ebef43041f230e799f1efd3a93e41f875c718da683...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.835343</td>\n",
       "      <td>108.830343</td>\n",
       "      <td>217.665686</td>\n",
       "      <td>27.208836</td>\n",
       "      <td>54.415171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000101</th>\n",
       "      <td>0197692748ba894697a0a48fdfdb3e72f3275b079005ef...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>118.901583</td>\n",
       "      <td>118.896583</td>\n",
       "      <td>237.798167</td>\n",
       "      <td>59.450792</td>\n",
       "      <td>59.448292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000102</th>\n",
       "      <td>abfc344cb5cfc51ce924a3d71fdfca158f390185feaaa2...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.830343</td>\n",
       "      <td>8.829843</td>\n",
       "      <td>17.660186</td>\n",
       "      <td>8.830343</td>\n",
       "      <td>4.414921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000103</th>\n",
       "      <td>f5f39c652586b1a623f8f1549d793ff9724e5583c25882...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.892783</td>\n",
       "      <td>22.892583</td>\n",
       "      <td>45.785367</td>\n",
       "      <td>11.446392</td>\n",
       "      <td>11.446292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000104</th>\n",
       "      <td>cc827939ae3abec82f24f25e5c40518ff0845159b64374...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>492.043821</td>\n",
       "      <td>492.043821</td>\n",
       "      <td>984.087642</td>\n",
       "      <td>164.014607</td>\n",
       "      <td>246.021910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000105 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tx_hash  indegree  \\\n",
       "0        0437cd7f8525ceed2324359c2d0ba26006d92d856a9c20...       0.0   \n",
       "1        f4184fc596403b9d638783cf57adfe4c75c605f6356fbc...       1.0   \n",
       "2        ea44e97271691990157559d0bdd9959e02790c34db6c00...       1.0   \n",
       "3        a16f3ce4dd5deb92d98ef5cf8afeaf0775ebca408f708b...       1.0   \n",
       "4        591e91f809d716912ca1d4a9295e70c3e78bab077683f7...       1.0   \n",
       "...                                                    ...       ...   \n",
       "1000100  3a66ebef43041f230e799f1efd3a93e41f875c718da683...       4.0   \n",
       "1000101  0197692748ba894697a0a48fdfdb3e72f3275b079005ef...       2.0   \n",
       "1000102  abfc344cb5cfc51ce924a3d71fdfca158f390185feaaa2...       1.0   \n",
       "1000103  f5f39c652586b1a623f8f1549d793ff9724e5583c25882...       2.0   \n",
       "1000104  cc827939ae3abec82f24f25e5c40518ff0845159b64374...       3.0   \n",
       "\n",
       "         outdegree      in_btc     out_btc   total_btc  mean_in_btc  \\\n",
       "0              1.0    0.000000   50.000000   50.000000     0.000000   \n",
       "1              2.0   50.000000   50.000000  100.000000    50.000000   \n",
       "2              1.0   10.000000   10.000000   20.000000    10.000000   \n",
       "3              1.0   40.000000   30.000000   70.000000    40.000000   \n",
       "4              2.0   30.000000   30.000000   60.000000    30.000000   \n",
       "...            ...         ...         ...         ...          ...   \n",
       "1000100        2.0  108.835343  108.830343  217.665686    27.208836   \n",
       "1000101        2.0  118.901583  118.896583  237.798167    59.450792   \n",
       "1000102        2.0    8.830343    8.829843   17.660186     8.830343   \n",
       "1000103        2.0   22.892783   22.892583   45.785367    11.446392   \n",
       "1000104        2.0  492.043821  492.043821  984.087642   164.014607   \n",
       "\n",
       "         mean_out_btc  in_malicious  out_malicious  is_malicious  \\\n",
       "0           50.000000           0.0            0.0           0.0   \n",
       "1           25.000000           0.0            0.0           0.0   \n",
       "2           10.000000           0.0            0.0           0.0   \n",
       "3           30.000000           0.0            0.0           0.0   \n",
       "4           15.000000           0.0            0.0           0.0   \n",
       "...               ...           ...            ...           ...   \n",
       "1000100     54.415171           0.0            0.0           1.0   \n",
       "1000101     59.448292           0.0            0.0           1.0   \n",
       "1000102      4.414921           0.0            1.0           0.0   \n",
       "1000103     11.446292           0.0            1.0           0.0   \n",
       "1000104    246.021910           0.0            1.0           0.0   \n",
       "\n",
       "         all_malicious  out_and_tx_malicious  \n",
       "0                  0.0                   0.0  \n",
       "1                  0.0                   0.0  \n",
       "2                  0.0                   0.0  \n",
       "3                  0.0                   0.0  \n",
       "4                  0.0                   0.0  \n",
       "...                ...                   ...  \n",
       "1000100            1.0                   1.0  \n",
       "1000101            1.0                   1.0  \n",
       "1000102            1.0                   1.0  \n",
       "1000103            1.0                   1.0  \n",
       "1000104            1.0                   1.0  \n",
       "\n",
       "[1000105 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3569652-ff52-4bb9-aeb2-06704043128a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_malicious</th>\n",
       "      <th>in_btc</th>\n",
       "      <th>in_malicious</th>\n",
       "      <th>indegree</th>\n",
       "      <th>is_malicious</th>\n",
       "      <th>mean_in_btc</th>\n",
       "      <th>mean_out_btc</th>\n",
       "      <th>out_and_tx_malicious</th>\n",
       "      <th>out_btc</th>\n",
       "      <th>out_malicious</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>total_btc</th>\n",
       "      <th>tx_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25000.620000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.302552</td>\n",
       "      <td>12500.005000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25000.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50000.630000</td>\n",
       "      <td>4885ddf124a0f97b5a3775a12de0274d342d12842ebe59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1720.151291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.724714</td>\n",
       "      <td>860.005646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1720.011291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3440.162582</td>\n",
       "      <td>48819d9d09c34df32feb1de0c4a54b9303031548cdd16c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>12500.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>d878b5784c2c1f6642d83faeab86e97faba758b2733a57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.688450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137690</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.368450</td>\n",
       "      <td>e3c8d10c304139a162f3147df38e38aa2f3d54ce5029b7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>51654fc7b8c059252e5104a532a6395f255c8c0b23d24b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1.0</td>\n",
       "      <td>108.835343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.208836</td>\n",
       "      <td>54.415171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.830343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>217.665686</td>\n",
       "      <td>3a66ebef43041f230e799f1efd3a93e41f875c718da683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.0</td>\n",
       "      <td>118.901583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.450792</td>\n",
       "      <td>59.448292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.896583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>237.798167</td>\n",
       "      <td>0197692748ba894697a0a48fdfdb3e72f3275b079005ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.830343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.830343</td>\n",
       "      <td>4.414921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.829843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.660186</td>\n",
       "      <td>abfc344cb5cfc51ce924a3d71fdfca158f390185feaaa2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.892783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.446392</td>\n",
       "      <td>11.446292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.892583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.785367</td>\n",
       "      <td>f5f39c652586b1a623f8f1549d793ff9724e5583c25882...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.0</td>\n",
       "      <td>492.043821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.014607</td>\n",
       "      <td>246.021910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>492.043821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>984.087642</td>\n",
       "      <td>cc827939ae3abec82f24f25e5c40518ff0845159b64374...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     all_malicious        in_btc  in_malicious  indegree  is_malicious  \\\n",
       "0              1.0  25000.620000           0.0     478.0           1.0   \n",
       "1              1.0   1720.151291           0.0      83.0           0.0   \n",
       "2              1.0  25000.000000           0.0       1.0           0.0   \n",
       "3              1.0      0.688450           0.0       5.0           0.0   \n",
       "4              1.0      0.225000           0.0       2.0           0.0   \n",
       "..             ...           ...           ...       ...           ...   \n",
       "103            1.0    108.835343           0.0       4.0           1.0   \n",
       "104            1.0    118.901583           0.0       2.0           1.0   \n",
       "105            1.0      8.830343           0.0       1.0           0.0   \n",
       "106            1.0     22.892783           0.0       2.0           0.0   \n",
       "107            1.0    492.043821           0.0       3.0           0.0   \n",
       "\n",
       "      mean_in_btc  mean_out_btc  out_and_tx_malicious       out_btc  \\\n",
       "0       52.302552  12500.005000                   1.0  25000.010000   \n",
       "1       20.724714    860.005646                   1.0   1720.011291   \n",
       "2    25000.000000  12500.000000                   1.0  25000.000000   \n",
       "3        0.137690      0.680000                   1.0      0.680000   \n",
       "4        0.112500      0.220000                   1.0      0.220000   \n",
       "..            ...           ...                   ...           ...   \n",
       "103     27.208836     54.415171                   1.0    108.830343   \n",
       "104     59.450792     59.448292                   1.0    118.896583   \n",
       "105      8.830343      4.414921                   1.0      8.829843   \n",
       "106     11.446392     11.446292                   1.0     22.892583   \n",
       "107    164.014607    246.021910                   1.0    492.043821   \n",
       "\n",
       "     out_malicious  outdegree     total_btc  \\\n",
       "0              0.0        2.0  50000.630000   \n",
       "1              1.0        2.0   3440.162582   \n",
       "2              1.0        2.0  50000.000000   \n",
       "3              1.0        1.0      1.368450   \n",
       "4              1.0        1.0      0.445000   \n",
       "..             ...        ...           ...   \n",
       "103            0.0        2.0    217.665686   \n",
       "104            0.0        2.0    237.798167   \n",
       "105            1.0        2.0     17.660186   \n",
       "106            1.0        2.0     45.785367   \n",
       "107            1.0        2.0    984.087642   \n",
       "\n",
       "                                               tx_hash  \n",
       "0    4885ddf124a0f97b5a3775a12de0274d342d12842ebe59...  \n",
       "1    48819d9d09c34df32feb1de0c4a54b9303031548cdd16c...  \n",
       "2    d878b5784c2c1f6642d83faeab86e97faba758b2733a57...  \n",
       "3    e3c8d10c304139a162f3147df38e38aa2f3d54ce5029b7...  \n",
       "4    51654fc7b8c059252e5104a532a6395f255c8c0b23d24b...  \n",
       "..                                                 ...  \n",
       "103  3a66ebef43041f230e799f1efd3a93e41f875c718da683...  \n",
       "104  0197692748ba894697a0a48fdfdb3e72f3275b079005ef...  \n",
       "105  abfc344cb5cfc51ce924a3d71fdfca158f390185feaaa2...  \n",
       "106  f5f39c652586b1a623f8f1549d793ff9724e5583c25882...  \n",
       "107  cc827939ae3abec82f24f25e5c40518ff0845159b64374...  \n",
       "\n",
       "[108 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "file2.drop('Unnamed: 0.1', axis=1, inplace=True)\n",
    "file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb4e35af-2bd9-42f2-85f4-8aff0582a2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tx_hash</th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>in_btc</th>\n",
       "      <th>out_btc</th>\n",
       "      <th>total_btc</th>\n",
       "      <th>mean_in_btc</th>\n",
       "      <th>mean_out_btc</th>\n",
       "      <th>in_malicious</th>\n",
       "      <th>out_malicious</th>\n",
       "      <th>is_malicious</th>\n",
       "      <th>all_malicious</th>\n",
       "      <th>out_and_tx_malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0437cd7f8525ceed2324359c2d0ba26006d92d856a9c20...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0cc917bf15f8807f224e7524c1eca22c3740ddefb7bf66...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>04256336e9287f3b46508888cf3539dc0ab2fc8803cbe9...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>b6c967d8f3a3d5fe859a12e9f385531655c2c457326845...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5439c37c4c6dad4ad93b1d5598d57f1aace9d0f68b8922...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000060</th>\n",
       "      <td>6f85951bcecbe64999ad192275af087c5be2922ee13937...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8872.221959</td>\n",
       "      <td>8872.221959</td>\n",
       "      <td>17744.443918</td>\n",
       "      <td>887.222196</td>\n",
       "      <td>4436.110980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000070</th>\n",
       "      <td>a2b642bafea45bc128d81314ef33542bc807811ba06632...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.041475</td>\n",
       "      <td>50.041475</td>\n",
       "      <td>100.082950</td>\n",
       "      <td>50.041475</td>\n",
       "      <td>25.020738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000080</th>\n",
       "      <td>0723b67631588b6d5a4a406a9ef8d431c0d5282c6f1cb3...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.889561</td>\n",
       "      <td>97.889561</td>\n",
       "      <td>195.779122</td>\n",
       "      <td>97.889561</td>\n",
       "      <td>48.944780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000090</th>\n",
       "      <td>6613d106b9d6e87438b0775c43a9581ec6a8bace86c7c5...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000100</th>\n",
       "      <td>3a66ebef43041f230e799f1efd3a93e41f875c718da683...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.835343</td>\n",
       "      <td>108.830343</td>\n",
       "      <td>217.665686</td>\n",
       "      <td>27.208836</td>\n",
       "      <td>54.415171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100011 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tx_hash  indegree  \\\n",
       "0        0437cd7f8525ceed2324359c2d0ba26006d92d856a9c20...       0.0   \n",
       "10       0cc917bf15f8807f224e7524c1eca22c3740ddefb7bf66...       0.0   \n",
       "20       04256336e9287f3b46508888cf3539dc0ab2fc8803cbe9...       0.0   \n",
       "30       b6c967d8f3a3d5fe859a12e9f385531655c2c457326845...       0.0   \n",
       "40       5439c37c4c6dad4ad93b1d5598d57f1aace9d0f68b8922...       2.0   \n",
       "...                                                    ...       ...   \n",
       "1000060  6f85951bcecbe64999ad192275af087c5be2922ee13937...      10.0   \n",
       "1000070  a2b642bafea45bc128d81314ef33542bc807811ba06632...       1.0   \n",
       "1000080  0723b67631588b6d5a4a406a9ef8d431c0d5282c6f1cb3...       1.0   \n",
       "1000090  6613d106b9d6e87438b0775c43a9581ec6a8bace86c7c5...       7.0   \n",
       "1000100  3a66ebef43041f230e799f1efd3a93e41f875c718da683...       4.0   \n",
       "\n",
       "         outdegree       in_btc      out_btc     total_btc  mean_in_btc  \\\n",
       "0              1.0     0.000000    50.000000     50.000000     0.000000   \n",
       "10             1.0     0.000000    50.000000     50.000000     0.000000   \n",
       "20             1.0     0.000000    50.000000     50.000000     0.000000   \n",
       "30             1.0     0.000000    50.000000     50.000000     0.000000   \n",
       "40             0.0   100.000000     0.000000    100.000000    50.000000   \n",
       "...            ...          ...          ...           ...          ...   \n",
       "1000060        2.0  8872.221959  8872.221959  17744.443918   887.222196   \n",
       "1000070        2.0    50.041475    50.041475    100.082950    50.041475   \n",
       "1000080        2.0    97.889561    97.889561    195.779122    97.889561   \n",
       "1000090        2.0   350.000000   350.000000    700.000000    50.000000   \n",
       "1000100        2.0   108.835343   108.830343    217.665686    27.208836   \n",
       "\n",
       "         mean_out_btc  in_malicious  out_malicious  is_malicious  \\\n",
       "0           50.000000           0.0            0.0           0.0   \n",
       "10          50.000000           0.0            0.0           0.0   \n",
       "20          50.000000           0.0            0.0           0.0   \n",
       "30          50.000000           0.0            0.0           0.0   \n",
       "40           0.000000           0.0            0.0           0.0   \n",
       "...               ...           ...            ...           ...   \n",
       "1000060   4436.110980           0.0            1.0           1.0   \n",
       "1000070     25.020738           0.0            0.0           1.0   \n",
       "1000080     48.944780           0.0            0.0           1.0   \n",
       "1000090    175.000000           0.0            1.0           0.0   \n",
       "1000100     54.415171           0.0            0.0           1.0   \n",
       "\n",
       "         all_malicious  out_and_tx_malicious  \n",
       "0                  0.0                   0.0  \n",
       "10                 0.0                   0.0  \n",
       "20                 0.0                   0.0  \n",
       "30                 0.0                   0.0  \n",
       "40                 0.0                   0.0  \n",
       "...                ...                   ...  \n",
       "1000060            1.0                   1.0  \n",
       "1000070            1.0                   1.0  \n",
       "1000080            1.0                   1.0  \n",
       "1000090            1.0                   1.0  \n",
       "1000100            1.0                   1.0  \n",
       "\n",
       "[100011 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1 = file1[::10]\n",
    "file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c97bc4-5881-4f01-a268-e70024df32a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tx_hash</th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>in_btc</th>\n",
       "      <th>out_btc</th>\n",
       "      <th>total_btc</th>\n",
       "      <th>mean_in_btc</th>\n",
       "      <th>mean_out_btc</th>\n",
       "      <th>in_malicious</th>\n",
       "      <th>out_malicious</th>\n",
       "      <th>is_malicious</th>\n",
       "      <th>all_malicious</th>\n",
       "      <th>out_and_tx_malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0437cd7f8525ceed2324359c2d0ba26006d92d856a9c20...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0cc917bf15f8807f224e7524c1eca22c3740ddefb7bf66...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>04256336e9287f3b46508888cf3539dc0ab2fc8803cbe9...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>b6c967d8f3a3d5fe859a12e9f385531655c2c457326845...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5439c37c4c6dad4ad93b1d5598d57f1aace9d0f68b8922...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3a66ebef43041f230e799f1efd3a93e41f875c718da683...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.835343</td>\n",
       "      <td>108.830343</td>\n",
       "      <td>217.665686</td>\n",
       "      <td>27.208836</td>\n",
       "      <td>54.415171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0197692748ba894697a0a48fdfdb3e72f3275b079005ef...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>118.901583</td>\n",
       "      <td>118.896583</td>\n",
       "      <td>237.798167</td>\n",
       "      <td>59.450792</td>\n",
       "      <td>59.448292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>abfc344cb5cfc51ce924a3d71fdfca158f390185feaaa2...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.830343</td>\n",
       "      <td>8.829843</td>\n",
       "      <td>17.660186</td>\n",
       "      <td>8.830343</td>\n",
       "      <td>4.414921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>f5f39c652586b1a623f8f1549d793ff9724e5583c25882...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.892783</td>\n",
       "      <td>22.892583</td>\n",
       "      <td>45.785367</td>\n",
       "      <td>11.446392</td>\n",
       "      <td>11.446292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>cc827939ae3abec82f24f25e5c40518ff0845159b64374...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>492.043821</td>\n",
       "      <td>492.043821</td>\n",
       "      <td>984.087642</td>\n",
       "      <td>164.014607</td>\n",
       "      <td>246.021910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100119 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tx_hash  indegree  outdegree  \\\n",
       "0    0437cd7f8525ceed2324359c2d0ba26006d92d856a9c20...       0.0        1.0   \n",
       "10   0cc917bf15f8807f224e7524c1eca22c3740ddefb7bf66...       0.0        1.0   \n",
       "20   04256336e9287f3b46508888cf3539dc0ab2fc8803cbe9...       0.0        1.0   \n",
       "30   b6c967d8f3a3d5fe859a12e9f385531655c2c457326845...       0.0        1.0   \n",
       "40   5439c37c4c6dad4ad93b1d5598d57f1aace9d0f68b8922...       2.0        0.0   \n",
       "..                                                 ...       ...        ...   \n",
       "103  3a66ebef43041f230e799f1efd3a93e41f875c718da683...       4.0        2.0   \n",
       "104  0197692748ba894697a0a48fdfdb3e72f3275b079005ef...       2.0        2.0   \n",
       "105  abfc344cb5cfc51ce924a3d71fdfca158f390185feaaa2...       1.0        2.0   \n",
       "106  f5f39c652586b1a623f8f1549d793ff9724e5583c25882...       2.0        2.0   \n",
       "107  cc827939ae3abec82f24f25e5c40518ff0845159b64374...       3.0        2.0   \n",
       "\n",
       "         in_btc     out_btc   total_btc  mean_in_btc  mean_out_btc  \\\n",
       "0      0.000000   50.000000   50.000000     0.000000     50.000000   \n",
       "10     0.000000   50.000000   50.000000     0.000000     50.000000   \n",
       "20     0.000000   50.000000   50.000000     0.000000     50.000000   \n",
       "30     0.000000   50.000000   50.000000     0.000000     50.000000   \n",
       "40   100.000000    0.000000  100.000000    50.000000      0.000000   \n",
       "..          ...         ...         ...          ...           ...   \n",
       "103  108.835343  108.830343  217.665686    27.208836     54.415171   \n",
       "104  118.901583  118.896583  237.798167    59.450792     59.448292   \n",
       "105    8.830343    8.829843   17.660186     8.830343      4.414921   \n",
       "106   22.892783   22.892583   45.785367    11.446392     11.446292   \n",
       "107  492.043821  492.043821  984.087642   164.014607    246.021910   \n",
       "\n",
       "     in_malicious  out_malicious  is_malicious  all_malicious  \\\n",
       "0             0.0            0.0           0.0            0.0   \n",
       "10            0.0            0.0           0.0            0.0   \n",
       "20            0.0            0.0           0.0            0.0   \n",
       "30            0.0            0.0           0.0            0.0   \n",
       "40            0.0            0.0           0.0            0.0   \n",
       "..            ...            ...           ...            ...   \n",
       "103           0.0            0.0           1.0            1.0   \n",
       "104           0.0            0.0           1.0            1.0   \n",
       "105           0.0            1.0           0.0            1.0   \n",
       "106           0.0            1.0           0.0            1.0   \n",
       "107           0.0            1.0           0.0            1.0   \n",
       "\n",
       "     out_and_tx_malicious  \n",
       "0                     0.0  \n",
       "10                    0.0  \n",
       "20                    0.0  \n",
       "30                    0.0  \n",
       "40                    0.0  \n",
       "..                    ...  \n",
       "103                   1.0  \n",
       "104                   1.0  \n",
       "105                   1.0  \n",
       "106                   1.0  \n",
       "107                   1.0  \n",
       "\n",
       "[100119 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = file1.append(file2)\n",
    "df = merged\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f3a788-2128-48e1-96bd-f509c36a7f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff906f3-2744-4a57-8ffa-07d6d392fdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    100000\n",
       "1.0       119\n",
       "Name: out_and_tx_malicious, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['out_and_tx_malicious'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d270bf1f-37d3-4e23-941f-417385f25ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100119 entries, 0 to 107\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   tx_hash               100119 non-null  object \n",
      " 1   indegree              100119 non-null  float64\n",
      " 2   outdegree             100119 non-null  float64\n",
      " 3   in_btc                100119 non-null  float64\n",
      " 4   out_btc               100119 non-null  float64\n",
      " 5   total_btc             100119 non-null  float64\n",
      " 6   mean_in_btc           100119 non-null  float64\n",
      " 7   mean_out_btc          100119 non-null  float64\n",
      " 8   in_malicious          100119 non-null  float64\n",
      " 9   out_malicious         100119 non-null  float64\n",
      " 10  is_malicious          100119 non-null  float64\n",
      " 11  all_malicious         100119 non-null  float64\n",
      " 12  out_and_tx_malicious  100119 non-null  float64\n",
      "dtypes: float64(12), object(1)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aefc157e-1e23-43b3-8b1e-4f6d2a10dcb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>in_btc</th>\n",
       "      <th>out_btc</th>\n",
       "      <th>total_btc</th>\n",
       "      <th>mean_in_btc</th>\n",
       "      <th>mean_out_btc</th>\n",
       "      <th>in_malicious</th>\n",
       "      <th>out_malicious</th>\n",
       "      <th>is_malicious</th>\n",
       "      <th>all_malicious</th>\n",
       "      <th>out_and_tx_malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100119.000000</td>\n",
       "      <td>100119.000000</td>\n",
       "      <td>100119.000000</td>\n",
       "      <td>100119.000000</td>\n",
       "      <td>100119.000000</td>\n",
       "      <td>100119.000000</td>\n",
       "      <td>100119.000000</td>\n",
       "      <td>100119.000000</td>\n",
       "      <td>100119.000000</td>\n",
       "      <td>100119.000000</td>\n",
       "      <td>100119.000000</td>\n",
       "      <td>100119.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.597249</td>\n",
       "      <td>1.832579</td>\n",
       "      <td>159.557526</td>\n",
       "      <td>159.677100</td>\n",
       "      <td>319.234626</td>\n",
       "      <td>144.144037</td>\n",
       "      <td>94.737911</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.804928</td>\n",
       "      <td>5.122187</td>\n",
       "      <td>2653.112747</td>\n",
       "      <td>2519.014262</td>\n",
       "      <td>5108.710007</td>\n",
       "      <td>2555.192513</td>\n",
       "      <td>1484.593025</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.026807</td>\n",
       "      <td>0.022784</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.034456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293250</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.897125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.770000</td>\n",
       "      <td>20.989000</td>\n",
       "      <td>43.431500</td>\n",
       "      <td>7.155000</td>\n",
       "      <td>11.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.650000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>96.920000</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>901.000000</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            indegree      outdegree         in_btc        out_btc  \\\n",
       "count  100119.000000  100119.000000  100119.000000  100119.000000   \n",
       "mean        1.597249       1.832579     159.557526     159.677100   \n",
       "std         5.804928       5.122187    2653.112747    2519.014262   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       0.293250       1.170000   \n",
       "50%         1.000000       2.000000       9.770000      20.989000   \n",
       "75%         1.000000       2.000000      48.650000      50.000000   \n",
       "max       901.000000     374.000000  400000.000000  400000.000000   \n",
       "\n",
       "           total_btc    mean_in_btc   mean_out_btc   in_malicious  \\\n",
       "count  100119.000000  100119.000000  100119.000000  100119.000000   \n",
       "mean      319.234626     144.144037      94.737911       0.000579   \n",
       "std      5108.710007    2555.192513    1484.593025       0.024062   \n",
       "min         0.000700       0.000000       0.000000       0.000000   \n",
       "25%         2.600000       0.200000       0.897125       0.000000   \n",
       "50%        43.431500       7.155000      11.460000       0.000000   \n",
       "75%        96.920000      46.100000      50.000000       0.000000   \n",
       "max    800000.000000  400000.000000  200000.000000       1.000000   \n",
       "\n",
       "       out_malicious   is_malicious  all_malicious  out_and_tx_malicious  \n",
       "count  100119.000000  100119.000000  100119.000000         100119.000000  \n",
       "mean        0.000719       0.000519       0.001728              0.001189  \n",
       "std         0.026807       0.022784       0.041533              0.034456  \n",
       "min         0.000000       0.000000       0.000000              0.000000  \n",
       "25%         0.000000       0.000000       0.000000              0.000000  \n",
       "50%         0.000000       0.000000       0.000000              0.000000  \n",
       "75%         0.000000       0.000000       0.000000              0.000000  \n",
       "max         1.000000       1.000000       1.000000              1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49284928-9a3b-44ac-b1d5-d53ef77aa87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>in_btc</th>\n",
       "      <th>out_btc</th>\n",
       "      <th>total_btc</th>\n",
       "      <th>mean_in_btc</th>\n",
       "      <th>mean_out_btc</th>\n",
       "      <th>out_and_tx_malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.835343</td>\n",
       "      <td>108.830343</td>\n",
       "      <td>217.665686</td>\n",
       "      <td>27.208836</td>\n",
       "      <td>54.415171</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>118.901583</td>\n",
       "      <td>118.896583</td>\n",
       "      <td>237.798167</td>\n",
       "      <td>59.450792</td>\n",
       "      <td>59.448292</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.830343</td>\n",
       "      <td>8.829843</td>\n",
       "      <td>17.660186</td>\n",
       "      <td>8.830343</td>\n",
       "      <td>4.414921</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.892783</td>\n",
       "      <td>22.892583</td>\n",
       "      <td>45.785367</td>\n",
       "      <td>11.446392</td>\n",
       "      <td>11.446292</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>492.043821</td>\n",
       "      <td>492.043821</td>\n",
       "      <td>984.087642</td>\n",
       "      <td>164.014607</td>\n",
       "      <td>246.021910</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100119 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     indegree  outdegree      in_btc     out_btc   total_btc  mean_in_btc  \\\n",
       "0         0.0        1.0    0.000000   50.000000   50.000000     0.000000   \n",
       "10        0.0        1.0    0.000000   50.000000   50.000000     0.000000   \n",
       "20        0.0        1.0    0.000000   50.000000   50.000000     0.000000   \n",
       "30        0.0        1.0    0.000000   50.000000   50.000000     0.000000   \n",
       "40        2.0        0.0  100.000000    0.000000  100.000000    50.000000   \n",
       "..        ...        ...         ...         ...         ...          ...   \n",
       "103       4.0        2.0  108.835343  108.830343  217.665686    27.208836   \n",
       "104       2.0        2.0  118.901583  118.896583  237.798167    59.450792   \n",
       "105       1.0        2.0    8.830343    8.829843   17.660186     8.830343   \n",
       "106       2.0        2.0   22.892783   22.892583   45.785367    11.446392   \n",
       "107       3.0        2.0  492.043821  492.043821  984.087642   164.014607   \n",
       "\n",
       "     mean_out_btc  out_and_tx_malicious  \n",
       "0       50.000000                   0.0  \n",
       "10      50.000000                   0.0  \n",
       "20      50.000000                   0.0  \n",
       "30      50.000000                   0.0  \n",
       "40       0.000000                   0.0  \n",
       "..            ...                   ...  \n",
       "103     54.415171                   1.0  \n",
       "104     59.448292                   1.0  \n",
       "105      4.414921                   1.0  \n",
       "106     11.446292                   1.0  \n",
       "107    246.021910                   1.0  \n",
       "\n",
       "[100119 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('tx_hash', axis=1, inplace=True)\n",
    "df.drop('in_malicious', axis=1, inplace=True)\n",
    "df.drop('out_malicious', axis=1, inplace=True)\n",
    "df.drop('is_malicious', axis=1, inplace=True)\n",
    "df.drop('all_malicious', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c107b4c-1016-46da-9c7a-328d07954fc8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['tx_hash'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5140\\2039064893.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tx_hash'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfile2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'in_malicious'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'out_malicious'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfile2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'is_malicious'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfile2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'all_malicious'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4174\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4175\u001b[0m         )\n\u001b[0;32m   4176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3887\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3888\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3889\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3891\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3922\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3923\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5286\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['tx_hash'] not found in axis\""
     ]
    }
   ],
   "source": [
    "file2.drop('tx_hash', axis=1, inplace=True)\n",
    "file2.drop('in_malicious', axis=1, inplace=True)\n",
    "file2.drop('out_malicious', axis=1, inplace=True)\n",
    "file2.drop('is_malicious', axis=1, inplace=True)\n",
    "file2.drop('all_malicious', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7432cc83-f3f0-4f1e-a6dc-5146a66f0f1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      478.0\n",
      "1       83.0\n",
      "2        1.0\n",
      "3        5.0\n",
      "4        2.0\n",
      "       ...  \n",
      "103      4.0\n",
      "104      2.0\n",
      "105      1.0\n",
      "106      2.0\n",
      "107      3.0\n",
      "Name: indegree, Length: 108, dtype: float64 0      2.0\n",
      "1      2.0\n",
      "2      2.0\n",
      "3      1.0\n",
      "4      1.0\n",
      "      ... \n",
      "103    2.0\n",
      "104    2.0\n",
      "105    2.0\n",
      "106    2.0\n",
      "107    2.0\n",
      "Name: outdegree, Length: 108, dtype: float64 0      25000.620000\n",
      "1       1720.151291\n",
      "2      25000.000000\n",
      "3          0.688450\n",
      "4          0.225000\n",
      "           ...     \n",
      "103      108.835343\n",
      "104      118.901583\n",
      "105        8.830343\n",
      "106       22.892783\n",
      "107      492.043821\n",
      "Name: in_btc, Length: 108, dtype: float64 0      25000.010000\n",
      "1       1720.011291\n",
      "2      25000.000000\n",
      "3          0.680000\n",
      "4          0.220000\n",
      "           ...     \n",
      "103      108.830343\n",
      "104      118.896583\n",
      "105        8.829843\n",
      "106       22.892583\n",
      "107      492.043821\n",
      "Name: out_btc, Length: 108, dtype: float64 0      50000.630000\n",
      "1       3440.162582\n",
      "2      50000.000000\n",
      "3          1.368450\n",
      "4          0.445000\n",
      "           ...     \n",
      "103      217.665686\n",
      "104      237.798167\n",
      "105       17.660186\n",
      "106       45.785367\n",
      "107      984.087642\n",
      "Name: total_btc, Length: 108, dtype: float64 0         52.302552\n",
      "1         20.724714\n",
      "2      25000.000000\n",
      "3          0.137690\n",
      "4          0.112500\n",
      "           ...     \n",
      "103       27.208836\n",
      "104       59.450792\n",
      "105        8.830343\n",
      "106       11.446392\n",
      "107      164.014607\n",
      "Name: mean_in_btc, Length: 108, dtype: float64 0      12500.005000\n",
      "1        860.005646\n",
      "2      12500.000000\n",
      "3          0.680000\n",
      "4          0.220000\n",
      "           ...     \n",
      "103       54.415171\n",
      "104       59.448292\n",
      "105        4.414921\n",
      "106       11.446292\n",
      "107      246.021910\n",
      "Name: mean_out_btc, Length: 108, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_btc</th>\n",
       "      <th>indegree</th>\n",
       "      <th>mean_in_btc</th>\n",
       "      <th>mean_out_btc</th>\n",
       "      <th>out_and_tx_malicious</th>\n",
       "      <th>out_btc</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>total_btc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25000.620000</td>\n",
       "      <td>478.0</td>\n",
       "      <td>52.302552</td>\n",
       "      <td>12500.005000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25000.010000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50000.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1720.151291</td>\n",
       "      <td>83.0</td>\n",
       "      <td>20.724714</td>\n",
       "      <td>860.005646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1720.011291</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3440.162582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25000.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>12500.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688450</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.137690</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.368450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>108.835343</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.208836</td>\n",
       "      <td>54.415171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.830343</td>\n",
       "      <td>2.0</td>\n",
       "      <td>217.665686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>118.901583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.450792</td>\n",
       "      <td>59.448292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.896583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>237.798167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>8.830343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.830343</td>\n",
       "      <td>4.414921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.829843</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.660186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>22.892783</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.446392</td>\n",
       "      <td>11.446292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.892583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.785367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>492.043821</td>\n",
       "      <td>3.0</td>\n",
       "      <td>164.014607</td>\n",
       "      <td>246.021910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>492.043821</td>\n",
       "      <td>2.0</td>\n",
       "      <td>984.087642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           in_btc  indegree   mean_in_btc  mean_out_btc  out_and_tx_malicious  \\\n",
       "0    25000.620000     478.0     52.302552  12500.005000                   1.0   \n",
       "1     1720.151291      83.0     20.724714    860.005646                   1.0   \n",
       "2    25000.000000       1.0  25000.000000  12500.000000                   1.0   \n",
       "3        0.688450       5.0      0.137690      0.680000                   1.0   \n",
       "4        0.225000       2.0      0.112500      0.220000                   1.0   \n",
       "..            ...       ...           ...           ...                   ...   \n",
       "103    108.835343       4.0     27.208836     54.415171                   1.0   \n",
       "104    118.901583       2.0     59.450792     59.448292                   1.0   \n",
       "105      8.830343       1.0      8.830343      4.414921                   1.0   \n",
       "106     22.892783       2.0     11.446392     11.446292                   1.0   \n",
       "107    492.043821       3.0    164.014607    246.021910                   1.0   \n",
       "\n",
       "          out_btc  outdegree     total_btc  \n",
       "0    25000.010000        2.0  50000.630000  \n",
       "1     1720.011291        2.0   3440.162582  \n",
       "2    25000.000000        2.0  50000.000000  \n",
       "3        0.680000        1.0      1.368450  \n",
       "4        0.220000        1.0      0.445000  \n",
       "..            ...        ...           ...  \n",
       "103    108.830343        2.0    217.665686  \n",
       "104    118.896583        2.0    237.798167  \n",
       "105      8.829843        2.0     17.660186  \n",
       "106     22.892583        2.0     45.785367  \n",
       "107    492.043821        2.0    984.087642  \n",
       "\n",
       "[108 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = file2['indegree']\n",
    "p2 = file2['outdegree']\n",
    "p3 = file2['in_btc']\n",
    "p4 = file2['out_btc']\n",
    "p5 = file2['total_btc']\n",
    "p6 = file2['mean_in_btc']\n",
    "p7 = file2['mean_out_btc']\n",
    "print(p1,p2,p3,p4,p5,p6,p7)\n",
    "file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff29e6dd-9bcc-4215-baf0-50fc82608de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df['out_and_tx_malicious'], test_size = 0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "419dfd3d-3ddf-451b-b029-dd668e41f47c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>in_btc</th>\n",
       "      <th>out_btc</th>\n",
       "      <th>total_btc</th>\n",
       "      <th>mean_in_btc</th>\n",
       "      <th>mean_out_btc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100430</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.28000</td>\n",
       "      <td>22.28000</td>\n",
       "      <td>44.56000</td>\n",
       "      <td>22.28000</td>\n",
       "      <td>11.14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758060</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.84000</td>\n",
       "      <td>6.83000</td>\n",
       "      <td>13.67000</td>\n",
       "      <td>3.42000</td>\n",
       "      <td>3.41500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800760</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.94412</td>\n",
       "      <td>18.94412</td>\n",
       "      <td>37.88824</td>\n",
       "      <td>18.94412</td>\n",
       "      <td>9.47206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160350</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>428.31000</td>\n",
       "      <td>428.26000</td>\n",
       "      <td>856.57000</td>\n",
       "      <td>428.31000</td>\n",
       "      <td>428.26000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317820</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.04000</td>\n",
       "      <td>73.66000</td>\n",
       "      <td>229.70000</td>\n",
       "      <td>156.04000</td>\n",
       "      <td>73.66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310190</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.62000</td>\n",
       "      <td>28.62000</td>\n",
       "      <td>57.24000</td>\n",
       "      <td>28.62000</td>\n",
       "      <td>14.31000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445660</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>49.98000</td>\n",
       "      <td>99.98000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>49.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958160</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.72750</td>\n",
       "      <td>36.72750</td>\n",
       "      <td>73.45500</td>\n",
       "      <td>36.72750</td>\n",
       "      <td>18.36375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721730</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.02000</td>\n",
       "      <td>3.02000</td>\n",
       "      <td>6.04000</td>\n",
       "      <td>3.02000</td>\n",
       "      <td>1.51000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892560</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15100</td>\n",
       "      <td>0.14850</td>\n",
       "      <td>0.29950</td>\n",
       "      <td>0.15100</td>\n",
       "      <td>0.14850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70083 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        indegree  outdegree     in_btc    out_btc  total_btc  mean_in_btc  \\\n",
       "100430       1.0        2.0   22.28000   22.28000   44.56000     22.28000   \n",
       "758060       2.0        2.0    6.84000    6.83000   13.67000      3.42000   \n",
       "800760       1.0        2.0   18.94412   18.94412   37.88824     18.94412   \n",
       "160350       1.0        1.0  428.31000  428.26000  856.57000    428.31000   \n",
       "317820       1.0        1.0  156.04000   73.66000  229.70000    156.04000   \n",
       "...          ...        ...        ...        ...        ...          ...   \n",
       "310190       1.0        2.0   28.62000   28.62000   57.24000     28.62000   \n",
       "445660       1.0        1.0   50.00000   49.98000   99.98000     50.00000   \n",
       "958160       1.0        2.0   36.72750   36.72750   73.45500     36.72750   \n",
       "721730       1.0        2.0    3.02000    3.02000    6.04000      3.02000   \n",
       "892560       1.0        1.0    0.15100    0.14850    0.29950      0.15100   \n",
       "\n",
       "        mean_out_btc  \n",
       "100430      11.14000  \n",
       "758060       3.41500  \n",
       "800760       9.47206  \n",
       "160350     428.26000  \n",
       "317820      73.66000  \n",
       "...              ...  \n",
       "310190      14.31000  \n",
       "445660      49.98000  \n",
       "958160      18.36375  \n",
       "721730       1.51000  \n",
       "892560       0.14850  \n",
       "\n",
       "[70083 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "009c5cc1-e1f5-46c8-9295-f0e4da2d9506",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111660    0.0\n",
       "440210    0.0\n",
       "903750    0.0\n",
       "291120    0.0\n",
       "147560    0.0\n",
       "         ... \n",
       "209590    0.0\n",
       "159060    0.0\n",
       "26490     0.0\n",
       "543730    0.0\n",
       "922260    0.0\n",
       "Name: out_and_tx_malicious, Length: 30036, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91618e99-9257-4c2a-9374-bec6e7d96ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# scaled_df = df.copy()\n",
    "# scaled_df['indegree'] = scaler.fit_transform(scaled_df['indegree'].values.reshape(-1,1))\n",
    "# scaled_df['outdegree']= scaler.fit_transform(scaled_df['outdegree'].values.reshape(-1,1))\n",
    "# scaled_df['in_btc'] = scaler.fit_transform(scaled_df['in_btc'].values.reshape(-1,1))\n",
    "# scaled_df['out_btc']= scaler.fit_transform(scaled_df['out_btc'].values.reshape(-1,1))\n",
    "# scaled_df['total_btc']= scaler.fit_transform(scaled_df['total_btc'].values.reshape(-1,1))\n",
    "# scaled_df['mean_in_btc']= scaler.fit_transform(scaled_df['mean_in_btc'].values.reshape(-1,1))\n",
    "# scaled_df['mean_out_btc']= scaler.fit_transform(scaled_df['mean_out_btc'].values.reshape(-1,1))\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f183839-8206-4f9b-a9ba-220bd701c7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70083, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ef827c1-28f3-44af-864f-20a4214d2b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70083,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83e9b3dd-7a89-4fc3-a192-59e505764f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 100116, 100117, 100118])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(row_count)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8eecee0-4439-4135-beb2-ad9c09a15b10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x, df['out_and_tx_malicious'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23afa7b5-9e7d-4116-896c-7b86fc938f76",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create some random data with values 0 and 1\n",
    "data = np.random.randint(2, size=100)\n",
    "\n",
    "# Create x-axis values\n",
    "x = np.arange(len(data))\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.scatter(x, data)\n",
    "\n",
    "# Add axis labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Data')\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e44cb551-1f32-444b-9a5a-81626c7fd4dc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>in_btc</th>\n",
       "      <th>out_btc</th>\n",
       "      <th>total_btc</th>\n",
       "      <th>mean_in_btc</th>\n",
       "      <th>mean_out_btc</th>\n",
       "      <th>out_and_tx_malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.275155</td>\n",
       "      <td>-0.162545</td>\n",
       "      <td>-0.060140</td>\n",
       "      <td>-0.043540</td>\n",
       "      <td>-0.052701</td>\n",
       "      <td>-0.056412</td>\n",
       "      <td>-0.030135</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.275155</td>\n",
       "      <td>-0.162545</td>\n",
       "      <td>-0.060140</td>\n",
       "      <td>-0.043540</td>\n",
       "      <td>-0.052701</td>\n",
       "      <td>-0.056412</td>\n",
       "      <td>-0.030135</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.275155</td>\n",
       "      <td>-0.162545</td>\n",
       "      <td>-0.060140</td>\n",
       "      <td>-0.043540</td>\n",
       "      <td>-0.052701</td>\n",
       "      <td>-0.056412</td>\n",
       "      <td>-0.030135</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.275155</td>\n",
       "      <td>-0.162545</td>\n",
       "      <td>-0.060140</td>\n",
       "      <td>-0.043540</td>\n",
       "      <td>-0.052701</td>\n",
       "      <td>-0.056412</td>\n",
       "      <td>-0.030135</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.069381</td>\n",
       "      <td>-0.357775</td>\n",
       "      <td>-0.022448</td>\n",
       "      <td>-0.063389</td>\n",
       "      <td>-0.042914</td>\n",
       "      <td>-0.036844</td>\n",
       "      <td>-0.063814</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.413918</td>\n",
       "      <td>0.032686</td>\n",
       "      <td>-0.019118</td>\n",
       "      <td>-0.020185</td>\n",
       "      <td>-0.019882</td>\n",
       "      <td>-0.045764</td>\n",
       "      <td>-0.027161</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.069381</td>\n",
       "      <td>0.032686</td>\n",
       "      <td>-0.015324</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>-0.015941</td>\n",
       "      <td>-0.033146</td>\n",
       "      <td>-0.023771</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-0.102887</td>\n",
       "      <td>0.032686</td>\n",
       "      <td>-0.056812</td>\n",
       "      <td>-0.059884</td>\n",
       "      <td>-0.059032</td>\n",
       "      <td>-0.052957</td>\n",
       "      <td>-0.060841</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.069381</td>\n",
       "      <td>0.032686</td>\n",
       "      <td>-0.051511</td>\n",
       "      <td>-0.054301</td>\n",
       "      <td>-0.053526</td>\n",
       "      <td>-0.051933</td>\n",
       "      <td>-0.056104</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.241649</td>\n",
       "      <td>0.032686</td>\n",
       "      <td>0.125320</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>0.130142</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.101903</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100119 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     indegree  outdegree    in_btc   out_btc  total_btc  mean_in_btc  \\\n",
       "0   -0.275155  -0.162545 -0.060140 -0.043540  -0.052701    -0.056412   \n",
       "10  -0.275155  -0.162545 -0.060140 -0.043540  -0.052701    -0.056412   \n",
       "20  -0.275155  -0.162545 -0.060140 -0.043540  -0.052701    -0.056412   \n",
       "30  -0.275155  -0.162545 -0.060140 -0.043540  -0.052701    -0.056412   \n",
       "40   0.069381  -0.357775 -0.022448 -0.063389  -0.042914    -0.036844   \n",
       "..        ...        ...       ...       ...        ...          ...   \n",
       "103  0.413918   0.032686 -0.019118 -0.020185  -0.019882    -0.045764   \n",
       "104  0.069381   0.032686 -0.015324 -0.016189  -0.015941    -0.033146   \n",
       "105 -0.102887   0.032686 -0.056812 -0.059884  -0.059032    -0.052957   \n",
       "106  0.069381   0.032686 -0.051511 -0.054301  -0.053526    -0.051933   \n",
       "107  0.241649   0.032686  0.125320  0.131944   0.130142     0.007777   \n",
       "\n",
       "     mean_out_btc  out_and_tx_malicious  \n",
       "0       -0.030135                   0.0  \n",
       "10      -0.030135                   0.0  \n",
       "20      -0.030135                   0.0  \n",
       "30      -0.030135                   0.0  \n",
       "40      -0.063814                   0.0  \n",
       "..            ...                   ...  \n",
       "103     -0.027161                   1.0  \n",
       "104     -0.023771                   1.0  \n",
       "105     -0.060841                   1.0  \n",
       "106     -0.056104                   1.0  \n",
       "107      0.101903                   1.0  \n",
       "\n",
       "[100119 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58a9c074-4e0b-43a4-8de7-1c199228a5cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df.iloc[:,:-1], scaled_df['out_and_tx_malicious'], test_size = 0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1df43ea2-240e-4054-84aa-8784c3a49d9c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70083, 7)\n",
      "(30036, 7)\n",
      "(70083,)\n",
      "(30036,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83905e0e-3df2-4c1a-8aaf-5d08fb6a7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49d25646-7f6f-4950-9510-350b6c83fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classification(X_train, y_train, X_test, y_test):\n",
    "    # initialize object for DecisionTreeClassifier class\n",
    "    dt_classifier = DecisionTreeClassifier()\n",
    "    # train model by using fit method\n",
    "    print(\"Model training starts........\")\n",
    "    dt_classifier.fit(X_train, y_train.values.ravel())\n",
    "    print(\"Model training completed\")\n",
    "    acc_score = dt_classifier.score(X_test, y_test)\n",
    "    print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    "    # predict result using test dataset\n",
    "    y_pred = dt_classifier.predict(X_test)\n",
    "    # confusion matrix\n",
    "    print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    "    # classification report for f1-score\n",
    "    print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    "    \n",
    "    with open('dt_model','wb') as f:\n",
    "        pickle.dump(dt_classifier,f)\n",
    "    print(\"Saved as dt_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2c380ea-e40b-4770-84b9-15ef7fab669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training starts........\n",
      "Model training completed\n",
      "Accuracy of model on test dataset :- 0.9982687441736583\n",
      "Confusion Matrix :- \n",
      " [[29982    24]\n",
      " [   28     2]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     30006\n",
      "         1.0       0.08      0.07      0.07        30\n",
      "\n",
      "    accuracy                           1.00     30036\n",
      "   macro avg       0.54      0.53      0.54     30036\n",
      "weighted avg       1.00      1.00      1.00     30036\n",
      "\n",
      "Saved as dt_model\n"
     ]
    }
   ],
   "source": [
    "decision_tree_classification(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b897ccac-e8a0-4e81-8a01-c455d37247c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training starts........\n",
      "Accuracy of model on test dataset :- 0.9989679051804501\n",
      "Confusion Matrix :- \n",
      " [[30002     4]\n",
      " [   27     3]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     30006\n",
      "         1.0       0.43      0.10      0.16        30\n",
      "\n",
      "    accuracy                           1.00     30036\n",
      "   macro avg       0.71      0.55      0.58     30036\n",
      "weighted avg       1.00      1.00      1.00     30036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    "     # initialize object for DecisionTreeClassifier class\n",
    "     rf_classifier = RandomForestClassifier(n_estimators=50)\n",
    "     # train model by using fit method\n",
    "     print(\"Model training starts........\")\n",
    "     rf_classifier.fit(X_train, y_train.values.ravel())\n",
    "     acc_score = rf_classifier.score(X_test, y_test)\n",
    "     print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    "     # predict result using test dataset\n",
    "     y_pred = rf_classifier.predict(X_test)\n",
    "     # confusion matrix\n",
    "     print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    "     # classification report for f1-score\n",
    "     print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "# calling random_forest_classifier\n",
    "random_forest_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32c9f01c-1974-4bdf-9161-ab3560f6be1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (139988, 7)\n",
      "After OverSampling, the shape of train_y: (139988,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(sampling_strategy='all')\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a40c35a3-5517-488f-9727-9fbc96b45851",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "139983    1.0\n",
       "139984    1.0\n",
       "139985    1.0\n",
       "139986    1.0\n",
       "139987    1.0\n",
       "Length: 139988, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20238fc9-0626-481f-85b9-39d4a5ae348e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(len(X_train_res))\n",
    "plt.scatter(x, y_train_res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4a80c47-2276-4112-b692-d8fe353cebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41355723-1daa-4a14-99df-d286c31d453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_res = pd.Series(y_train_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5bf1807-acd7-4a7a-8e25-6f7dda93db1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    69994\n",
       "0.0    69994\n",
       "Name: out_and_tx_malicious, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d077a9eb-d00b-49cb-bde6-0b81c5deda40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training starts........\n",
      "Accuracy of model on test dataset :- 0.9530896257823944\n",
      "Confusion Matrix :- \n",
      " [[28619  1387]\n",
      " [   22     8]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.98     30006\n",
      "         1.0       0.01      0.27      0.01        30\n",
      "\n",
      "    accuracy                           0.95     30036\n",
      "   macro avg       0.50      0.61      0.49     30036\n",
      "weighted avg       1.00      0.95      0.98     30036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_classifier(X_train_res, y_train_res, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35fc83f8-6512-47d1-aece-a90ad6daa15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training starts........\n",
      "Model training completed\n",
      "Accuracy of model on test dataset :- 0.9512251964309495\n",
      "Confusion Matrix :- \n",
      " [[28565  1441]\n",
      " [   24     6]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.97     30006\n",
      "         1.0       0.00      0.20      0.01        30\n",
      "\n",
      "    accuracy                           0.95     30036\n",
      "   macro avg       0.50      0.58      0.49     30036\n",
      "weighted avg       1.00      0.95      0.97     30036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree_classification(X_train_res, y_train_res, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9647e353-ff72-4d63-9722-834583147186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "with open('dt_model', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "count = 0  \n",
    "for i in range(len(file2)):\n",
    "    model_prediction = model.predict([[p1[i],p2[i],p3[i],p4[i],p5[i],p6[i],p7[i]]])\n",
    "    if(model_prediction[0] == 1):\n",
    "        count = count + 1\n",
    "    \n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98f19e25-e542-4e5f-93e1-af0cf3bb1a2e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_val = scaled_df['out_and_tx_malicious'].value_counts()\n",
    "non_malicious = class_val[0]\n",
    "malicious = class_val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98b1f05f-58a0-41be-8560-44182894e7ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    100000\n",
       "1.0       119\n",
       "Name: out_and_tx_malicious, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56b80a78-215c-482f-8f4e-664ee1ba9d17",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_malicious_indices = scaled_df[scaled_df.out_and_tx_malicious == 0].index\n",
    "malicious_indices = np.array(scaled_df[scaled_df['out_and_tx_malicious'] == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af67770f-ad98-41ef-b9c3-2d78be7ddd5d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,     10,     20,     30,     40,     50,     60,     70,\n",
       "                80,     90,\n",
       "            ...\n",
       "            999900, 999910, 999920, 999930, 999940, 999950, 999960, 999970,\n",
       "            999980, 999990],\n",
       "           dtype='int64', length=100000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_malicious_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07abe8cf-ed92-4271-8abb-b57a6531b758",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(non_malicious_indices).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34869848-cfa1-47e6-a814-1df6b48b5c13",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_normal_indices = np.random.choice(non_malicious_indices, malicious, replace=False)\n",
    "random_normal_indices = np.array(random_normal_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "640d749e-7319-47ad-8000-f64ebc98de0b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32010, 569970, 160730, 969290,  58510, 960870, 182130, 495330,\n",
       "       519700, 498300, 460330, 754320, 337890, 358050,  27660, 298340,\n",
       "       350150, 981480, 429550, 190230, 149270, 664220, 110940, 393200,\n",
       "       636060, 596770, 252630, 922190, 930380, 918990, 621150, 570420,\n",
       "       432150, 531490, 517950, 934290, 284390,   2850, 371800, 526430,\n",
       "       104940, 570510, 460480, 912690, 121330, 395530, 592310, 511570,\n",
       "       651220, 444020, 266840, 196170, 504940, 936470, 804010, 858630,\n",
       "       536990, 267280, 857970, 297320, 946250, 207120, 412090, 429790,\n",
       "       280450,  82210, 174440, 642390, 769530, 823640, 898460, 911840,\n",
       "       771000, 908860, 788520, 572940, 187210, 878320, 250010, 111350,\n",
       "       605770, 991840, 718240, 260060, 569260, 850110, 162180, 268780,\n",
       "       654680, 384230, 196610, 441110, 671810, 775700, 424790, 209190,\n",
       "       820730, 974960, 632300, 593320, 881540, 611530, 721710, 507200,\n",
       "       334360, 517670, 152930, 707530, 895270, 919360, 213220, 473970,\n",
       "       960700, 605820, 631290, 691290, 637030, 205560, 193290],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_normal_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b463951-e00d-4915-a00e-e33bb5e8017f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1468\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1469\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1470\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3362\u001b[0m         \"\"\"\n\u001b[1;32m-> 3363\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3350\u001b[0m         new_data = self._mgr.take(\n\u001b[1;32m-> 3351\u001b[1;33m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3352\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexers.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"indices are out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6600\\3929121436.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#extract all features from whole data for under sample indices only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0munder_sample_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaled_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munder_sample_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(under_sample_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# now we have to divide under sampling data to all features & target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1485\u001b[0m         \u001b[1;31m# a list of integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1487\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1489\u001b[0m         \u001b[1;31m# a single integer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m             \u001b[1;31m# re-raise with different error message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "under_sample_indices = np.concatenate([malicious_indices, random_normal_indices])\n",
    "\n",
    "#extract all features from whole data for under sample indices only\n",
    "under_sample_data = scaled_df.iloc[under_sample_indices]\n",
    "# print(under_sample_data)\n",
    "# now we have to divide under sampling data to all features & target\n",
    "# x_undersample_data = under_sample_data.drop(['out_and_tx_malicious'], axis=1)\n",
    "# y_undersample_data = under_sample_data[['out_and_tx_malicious']]\n",
    "# # now split dataset to train and test datasets as before\n",
    "# X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(x_undersample_data, y_undersample_data, test_size=0.2, random_state=0)\n",
    "# y_undersample_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2367d16a-24f6-43e3-914c-6ddc86c51876",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "under_sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d9031-2555-4678-9368-a779089611e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "under_sample_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
